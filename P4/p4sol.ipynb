{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XHloNBL2t4H"
      },
      "source": [
        "# P4 Regularización, Normalización y Aumentado de datos\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYWZ8vGi2t4L"
      },
      "source": [
        "## Ejercicio:\n",
        "\n",
        "Probar todas las técnicas presentadas para obtener un acierto en test > 99%. Se aconseja no malgastar datos de entrenamiento y por lo tanto emplear todo el training set para el entrenamiento. No emplear conjunto de validación y emplear el test set al final para calcular el acierto final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viIRejJz2t4M",
        "outputId": "53795f3c-46e8-4330-b6c8-a97b1fd82477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training set (60000, 28, 28, 1)\n",
            "test set (10000, 28, 28, 1)\n",
            "Epoch 1/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.6899 - accuracy: 0.8047\n",
            "Epoch 1: val_accuracy improved from -inf to 0.93600, saving model to best_model.h5\n",
            "469/469 [==============================] - 31s 61ms/step - loss: 0.6893 - accuracy: 0.8048 - val_loss: 0.1980 - val_accuracy: 0.9360 - lr: 0.0100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.3211 - accuracy: 0.9016\n",
            "Epoch 2: val_accuracy improved from 0.93600 to 0.94760, saving model to best_model.h5\n",
            "469/469 [==============================] - 22s 48ms/step - loss: 0.3211 - accuracy: 0.9016 - val_loss: 0.1858 - val_accuracy: 0.9476 - lr: 0.0100\n",
            "Epoch 3/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.2462 - accuracy: 0.9234\n",
            "Epoch 3: val_accuracy improved from 0.94760 to 0.97280, saving model to best_model.h5\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.2461 - accuracy: 0.9234 - val_loss: 0.0835 - val_accuracy: 0.9728 - lr: 0.0100\n",
            "Epoch 4/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.2082 - accuracy: 0.9342\n",
            "Epoch 4: val_accuracy did not improve from 0.97280\n",
            "469/469 [==============================] - 22s 48ms/step - loss: 0.2082 - accuracy: 0.9341 - val_loss: 0.1297 - val_accuracy: 0.9554 - lr: 0.0100\n",
            "Epoch 5/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.1923 - accuracy: 0.9408\n",
            "Epoch 5: val_accuracy did not improve from 0.97280\n",
            "469/469 [==============================] - 21s 46ms/step - loss: 0.1922 - accuracy: 0.9408 - val_loss: 0.1013 - val_accuracy: 0.9678 - lr: 0.0100\n",
            "Epoch 6/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.1784 - accuracy: 0.9439\n",
            "Epoch 6: val_accuracy did not improve from 0.97280\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.1783 - accuracy: 0.9439 - val_loss: 0.0922 - val_accuracy: 0.9721 - lr: 0.0100\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1683 - accuracy: 0.9463\n",
            "Epoch 7: val_accuracy did not improve from 0.97280\n",
            "469/469 [==============================] - 21s 45ms/step - loss: 0.1683 - accuracy: 0.9463 - val_loss: 0.0969 - val_accuracy: 0.9702 - lr: 0.0100\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.9509\n",
            "Epoch 8: val_accuracy improved from 0.97280 to 0.97570, saving model to best_model.h5\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.1582 - accuracy: 0.9509 - val_loss: 0.0725 - val_accuracy: 0.9757 - lr: 0.0100\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1483 - accuracy: 0.9533\n",
            "Epoch 9: val_accuracy did not improve from 0.97570\n",
            "469/469 [==============================] - 22s 46ms/step - loss: 0.1483 - accuracy: 0.9533 - val_loss: 0.0928 - val_accuracy: 0.9692 - lr: 0.0100\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1458 - accuracy: 0.9550\n",
            "Epoch 10: val_accuracy improved from 0.97570 to 0.97580, saving model to best_model.h5\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.1458 - accuracy: 0.9550 - val_loss: 0.0724 - val_accuracy: 0.9758 - lr: 0.0100\n",
            "Epoch 11/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.1379 - accuracy: 0.9568\n",
            "Epoch 11: val_accuracy did not improve from 0.97580\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.1379 - accuracy: 0.9567 - val_loss: 0.1145 - val_accuracy: 0.9665 - lr: 0.0100\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1380 - accuracy: 0.9566\n",
            "Epoch 12: val_accuracy improved from 0.97580 to 0.97640, saving model to best_model.h5\n",
            "469/469 [==============================] - 21s 44ms/step - loss: 0.1380 - accuracy: 0.9566 - val_loss: 0.0771 - val_accuracy: 0.9764 - lr: 0.0100\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.9588\n",
            "Epoch 13: val_accuracy improved from 0.97640 to 0.98070, saving model to best_model.h5\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 0.1359 - accuracy: 0.9588 - val_loss: 0.0566 - val_accuracy: 0.9807 - lr: 0.0100\n",
            "Epoch 14/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.1291 - accuracy: 0.9602\n",
            "Epoch 14: val_accuracy did not improve from 0.98070\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.1290 - accuracy: 0.9603 - val_loss: 0.0619 - val_accuracy: 0.9804 - lr: 0.0100\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1244 - accuracy: 0.9622\n",
            "Epoch 15: val_accuracy did not improve from 0.98070\n",
            "469/469 [==============================] - 21s 44ms/step - loss: 0.1244 - accuracy: 0.9622 - val_loss: 0.0650 - val_accuracy: 0.9801 - lr: 0.0100\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1233 - accuracy: 0.9625\n",
            "Epoch 16: val_accuracy did not improve from 0.98070\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.1233 - accuracy: 0.9625 - val_loss: 0.0701 - val_accuracy: 0.9780 - lr: 0.0100\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1208 - accuracy: 0.9621\n",
            "Epoch 17: val_accuracy improved from 0.98070 to 0.98130, saving model to best_model.h5\n",
            "469/469 [==============================] - 20s 44ms/step - loss: 0.1208 - accuracy: 0.9621 - val_loss: 0.0591 - val_accuracy: 0.9813 - lr: 0.0100\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.9653\n",
            "Epoch 18: val_accuracy improved from 0.98130 to 0.98190, saving model to best_model.h5\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.1129 - accuracy: 0.9653 - val_loss: 0.0547 - val_accuracy: 0.9819 - lr: 0.0100\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.9651\n",
            "Epoch 19: val_accuracy did not improve from 0.98190\n",
            "469/469 [==============================] - 22s 47ms/step - loss: 0.1115 - accuracy: 0.9651 - val_loss: 0.0609 - val_accuracy: 0.9806 - lr: 0.0100\n",
            "Epoch 20/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.1098 - accuracy: 0.9659\n",
            "Epoch 20: val_accuracy improved from 0.98190 to 0.98480, saving model to best_model.h5\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 0.1097 - accuracy: 0.9660 - val_loss: 0.0515 - val_accuracy: 0.9848 - lr: 0.0100\n",
            "Epoch 21/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.1092 - accuracy: 0.9663\n",
            "Epoch 21: val_accuracy did not improve from 0.98480\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.1090 - accuracy: 0.9664 - val_loss: 0.0536 - val_accuracy: 0.9832 - lr: 0.0100\n",
            "Epoch 22/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.1076 - accuracy: 0.9663\n",
            "Epoch 22: val_accuracy did not improve from 0.98480\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.1078 - accuracy: 0.9662 - val_loss: 0.0576 - val_accuracy: 0.9828 - lr: 0.0100\n",
            "Epoch 23/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.1062 - accuracy: 0.9666\n",
            "Epoch 23: val_accuracy did not improve from 0.98480\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 0.1063 - accuracy: 0.9666 - val_loss: 0.0639 - val_accuracy: 0.9818 - lr: 0.0100\n",
            "Epoch 24/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0999 - accuracy: 0.9692\n",
            "Epoch 24: val_accuracy did not improve from 0.98480\n",
            "469/469 [==============================] - 20s 44ms/step - loss: 0.1001 - accuracy: 0.9692 - val_loss: 0.0517 - val_accuracy: 0.9837 - lr: 0.0100\n",
            "Epoch 25/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.1012 - accuracy: 0.9676\n",
            "Epoch 25: val_accuracy did not improve from 0.98480\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.1012 - accuracy: 0.9676 - val_loss: 0.0904 - val_accuracy: 0.9839 - lr: 0.0100\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.9692\n",
            "Epoch 26: val_accuracy did not improve from 0.98480\n",
            "469/469 [==============================] - 20s 44ms/step - loss: 0.0999 - accuracy: 0.9692 - val_loss: 0.0738 - val_accuracy: 0.9796 - lr: 0.0100\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.9704\n",
            "Epoch 27: val_accuracy did not improve from 0.98480\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.0942 - accuracy: 0.9704 - val_loss: 0.0516 - val_accuracy: 0.9842 - lr: 0.0100\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9717\n",
            "Epoch 28: val_accuracy did not improve from 0.98480\n",
            "469/469 [==============================] - 21s 46ms/step - loss: 0.0914 - accuracy: 0.9717 - val_loss: 0.0532 - val_accuracy: 0.9833 - lr: 0.0100\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9706\n",
            "Epoch 29: val_accuracy did not improve from 0.98480\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.0938 - accuracy: 0.9706 - val_loss: 0.0481 - val_accuracy: 0.9847 - lr: 0.0100\n",
            "Epoch 30/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0931 - accuracy: 0.9701\n",
            "Epoch 30: val_accuracy did not improve from 0.98480\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.0931 - accuracy: 0.9701 - val_loss: 0.0619 - val_accuracy: 0.9848 - lr: 0.0100\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9794\n",
            "Epoch 31: val_accuracy improved from 0.98480 to 0.99000, saving model to best_model.h5\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.0665 - accuracy: 0.9794 - val_loss: 0.0400 - val_accuracy: 0.9900 - lr: 0.0020\n",
            "Epoch 32/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0602 - accuracy: 0.9804\n",
            "Epoch 32: val_accuracy did not improve from 0.99000\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 0.0603 - accuracy: 0.9804 - val_loss: 0.0694 - val_accuracy: 0.9894 - lr: 0.0020\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.9812\n",
            "Epoch 33: val_accuracy did not improve from 0.99000\n",
            "469/469 [==============================] - 19s 42ms/step - loss: 0.0580 - accuracy: 0.9812 - val_loss: 0.0355 - val_accuracy: 0.9900 - lr: 0.0020\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9826\n",
            "Epoch 34: val_accuracy improved from 0.99000 to 0.99060, saving model to best_model.h5\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 0.0555 - accuracy: 0.9826 - val_loss: 0.0288 - val_accuracy: 0.9906 - lr: 0.0020\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9817\n",
            "Epoch 35: val_accuracy improved from 0.99060 to 0.99120, saving model to best_model.h5\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.0555 - accuracy: 0.9817 - val_loss: 0.0293 - val_accuracy: 0.9912 - lr: 0.0020\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9830\n",
            "Epoch 36: val_accuracy did not improve from 0.99120\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 0.0524 - accuracy: 0.9830 - val_loss: 0.0427 - val_accuracy: 0.9907 - lr: 0.0020\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9834\n",
            "Epoch 37: val_accuracy did not improve from 0.99120\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 0.0510 - accuracy: 0.9834 - val_loss: 0.0287 - val_accuracy: 0.9903 - lr: 0.0020\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9833\n",
            "Epoch 38: val_accuracy did not improve from 0.99120\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.0498 - accuracy: 0.9833 - val_loss: 0.0303 - val_accuracy: 0.9896 - lr: 0.0020\n",
            "Epoch 39/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 0.9838\n",
            "Epoch 39: val_accuracy did not improve from 0.99120\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.0515 - accuracy: 0.9837 - val_loss: 0.0283 - val_accuracy: 0.9908 - lr: 0.0020\n",
            "Epoch 40/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0489 - accuracy: 0.9843\n",
            "Epoch 40: val_accuracy did not improve from 0.99120\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 0.0488 - accuracy: 0.9843 - val_loss: 0.0278 - val_accuracy: 0.9909 - lr: 0.0020\n",
            "Epoch 41/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0497 - accuracy: 0.9843\n",
            "Epoch 41: val_accuracy improved from 0.99120 to 0.99130, saving model to best_model.h5\n",
            "469/469 [==============================] - 21s 45ms/step - loss: 0.0497 - accuracy: 0.9843 - val_loss: 0.0305 - val_accuracy: 0.9913 - lr: 0.0020\n",
            "Epoch 42/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0492 - accuracy: 0.9842\n",
            "Epoch 42: val_accuracy did not improve from 0.99130\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 0.0494 - accuracy: 0.9842 - val_loss: 0.0556 - val_accuracy: 0.9900 - lr: 0.0020\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9856\n",
            "Epoch 43: val_accuracy did not improve from 0.99130\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.0462 - accuracy: 0.9856 - val_loss: 0.0419 - val_accuracy: 0.9905 - lr: 4.0000e-04\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9854\n",
            "Epoch 44: val_accuracy did not improve from 0.99130\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 0.0445 - accuracy: 0.9854 - val_loss: 0.0259 - val_accuracy: 0.9910 - lr: 4.0000e-04\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9861\n",
            "Epoch 45: val_accuracy did not improve from 0.99130\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.0315 - val_accuracy: 0.9907 - lr: 4.0000e-04\n",
            "Epoch 46/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9858\n",
            "Epoch 46: val_accuracy did not improve from 0.99130\n",
            "469/469 [==============================] - 21s 44ms/step - loss: 0.0445 - accuracy: 0.9858 - val_loss: 0.0262 - val_accuracy: 0.9906 - lr: 4.0000e-04\n",
            "Epoch 47/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0430 - accuracy: 0.9863\n",
            "Epoch 47: val_accuracy did not improve from 0.99130\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.0430 - accuracy: 0.9863 - val_loss: 0.0283 - val_accuracy: 0.9910 - lr: 4.0000e-04\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9858\n",
            "Epoch 48: val_accuracy did not improve from 0.99130\n",
            "469/469 [==============================] - 22s 48ms/step - loss: 0.0433 - accuracy: 0.9858 - val_loss: 0.0253 - val_accuracy: 0.9913 - lr: 4.0000e-04\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9869\n",
            "Epoch 49: val_accuracy did not improve from 0.99130\n",
            "469/469 [==============================] - 21s 45ms/step - loss: 0.0417 - accuracy: 0.9869 - val_loss: 0.0372 - val_accuracy: 0.9913 - lr: 4.0000e-04\n",
            "Epoch 50/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9864\n",
            "Epoch 50: val_accuracy improved from 0.99130 to 0.99140, saving model to best_model.h5\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.0421 - accuracy: 0.9864 - val_loss: 0.0274 - val_accuracy: 0.9914 - lr: 4.0000e-04\n",
            "Test loss: 0.02741558477282524\n",
            "Test accuracy: 0.9914000034332275\n"
          ]
        }
      ],
      "source": [
        "## Solución\n",
        "\n",
        "\n",
        "# Importar y normalizar datos\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "print('training set', x_train.shape)\n",
        "print('test set', x_test.shape)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalize [0..255]-->[0..1]\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "num_classes=10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Input, BatchNormalization, Reshape\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Input, Dropout, BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Input((28,28,1)))\n",
        "model.add(Reshape((784,)))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "opt=Adam(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=opt,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=2, min_lr=0.00001)\n",
        "\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "\n",
        "epochs=50\n",
        "batch_size=128\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=[reduce_lr,checkpoint])\n",
        "\n",
        "## Cargar el mejor modelo y evaluarlo con el test set\n",
        "model = keras.models.load_model('best_model.h5')\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}