{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "Prueba los diferentes LRS sobre el modelo anterior. Emplea la que creas que es la mejor topología de red y optimizador. Emplea early stopping y model checkpoint. Calcula el accuracy sobre el test con el modelo almacenado en el model checkpoint.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emplear un LRS estandard de Keras: ReduceLROnPlateau\n",
    "# Aquí pueden emplear el que quieran, lo ideal es siempre lo mismo\n",
    "# probar con validación y sólo el mejor en test\n",
    "\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# se pueden probar otras topologías\n",
    "model.add(Input(784))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Se pueden probar otros Optimizadores \n",
    "opt=SGD(learning_rate=0.025, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "\n",
    "## Es complicado combinar EarlyStopping y LearningRateSchedulers porque ambos actúan cuando la métrica deja de descender\n",
    "#callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5) \n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "# Se pueden probr otros LRS\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=3, min_lr=0.00001)\n",
    "\n",
    "epochs=50\n",
    "batch_size=128\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[reduce_lr,checkpoint])  \n",
    "\n",
    "## Cargar el mejor modelo y evaluarlo con el test set\n",
    "model = keras.models.load_model('best_model.h5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
